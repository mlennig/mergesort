Design, implement and test a program capable of sorting up to 100,000 decimal numbers
(randomly generated and stored in a file; the sorted output should also be written to a file)
using (a) recursive and (b) loop-based implementations of merge-sort. Sort 1000, 11,000,
21,000, 31,000, … up to 91,000 numbers, recording the times (in either CPU cycles or
absolute time- if you’re running it on the same platform) that the actual sorting process
takes- not any reading or writing to files and the like. Plot a graph showing time vs. no. of
elements, for both implementations
